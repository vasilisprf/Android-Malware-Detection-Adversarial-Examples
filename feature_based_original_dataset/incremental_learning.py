import set_onehot_encoding as onehot
from sklearn.naive_bayes import MultinomialNB, ComplementNB
import neural_network as NN
import models
import numpy as np
import matplotlib.pyplot as plt
import joblib


def create_training_input():
    print("Generating TRAINING set...")
    training_set = onehot.generate_set_incremental(mini_batch_size, malware_ratio)  # choose random training set
    print("Generating TRAINING input...")
    data, labels = onehot.generate_input(training_set, total_features)  # perform one-hot encoding
    return data, labels


def create_testing_input():
    testing_set = []  # the list of testing set

    with open("testing_set_1500.txt", "r") as file:  # read testing set file and append applications to list
        for line in file:
            line.strip()
            line = line[:-1]
            testing_set.append(line)
    print("Generating TESTING input...")
    test_data, test_labels = onehot.generate_input(testing_set, total_features)  # perform one-hot encoding
    return test_data, test_labels


def incremental_learn():
    for j in range(batches):
        data, labels = create_training_input()

        # incremental train and evaluate Multinomial Naive Bayes
        #model = MNB.train_incremental(data, labels)
        #MNB.evaluate_multi_naive_bayes_classifier(model, x_test, y_test)

        # incremental train and evaluate Complement Naive Bayes
        #model = CNB.train_incremental(data, labels)
        #CNB.evaluate_complement_naive_bayes_classifier(model, x_test, y_test)

        # incremental train and evaluate neural net
        NN.train_neural_network(model, epochs, batch_size, data, labels)  # train neural network
        NN.evaluate_neural_network(model, x_test, y_test)

    #filename = "model_incremental_" + type(MNB).__name__ + ".joblib"
    #dump(model, filename)
    #MNB.test_multi_naive_bayes_classifier(model, x_test, y_test)

    #filename = "model_incremental_" + type(CNB).__name__ + ".joblib"
    #dump(model, filename)
    #CNB.test_complement_naive_bayes_classifier(model, x_test, y_test)

    opt_config = model.optimizer.get_config()

    if 'name' not in opt_config.keys():
        _name = str(model.optimizer.__class__).split('.')[-1].replace('\'', '').replace('>', '')
        opt_config.update({'name': _name})

    model.save('model_' + opt_config['name'] + '.h5')

    NN.test_neural_network(model, x_test, y_test)


if __name__ == "__main__":
    total_features = 545333  # total unique features
    mini_batch_size = 1000  # we will feed the classifier with mini batches of 1000.
    # number of times that mini batches will be fed to the classifier (the total number of samples will be batch_size*i)
    batches = 19

    testing_set_size = 1000  # set site that will be used to create random test set

    malware_ratio = 0.3  # malware ratio in the mini batch size

    training_data = []  # list of training batches
    training_labels = []  # list of testing samples

    MNB = models.MultinomialNaiveBayes()  # Multinomial Naive Bayes for incremental learning
    CNB = models.ComplementNaiveBayes()  # Complement Naive Bayes for incremental learning

    units = [200, 200]
    dropout = 0.2
    epochs = 4
    batch_size = 150
    learn_rate = 0.001
    kernel_initializer = 'glorot_uniform'
    bias_initializer = 'zeros'
    activation_function = 'relu'
    model = NN.generate_neural_network(total_features, units, dropout, learn_rate, kernel_initializer,
                                       bias_initializer, activation_function)

    print("Creating data-labels...")
    onehot.create_list_of_apps()  # function from set_one_encoding.py

    x_test, y_test = create_testing_input()
    incremental_learn()
