import tensorflow as tf
import numpy as np
from sklearn.metrics import confusion_matrix
import set_onehot_encoding as onehot
import os


def create_set():
    if os.path.isfile("testing_set_1000.txt") is False:
        set_size = 1000
        malware_ratio = 0.3
        print("Creating data-labels...")
        print("Generating TESTING set...")
        testing_set = onehot.generate_set(set_size, malware_ratio)  # generate random testing set
        with open("testing_set_1000.txt", "w") as file:
            for item in testing_set:
                file.write(str(item) + "\n")
    testing_set = []  # the list of testing set
    with open("testing_set_1000.txt", "r") as file:  # read testing set file and append applications to list
        for line in file:
            line.strip()
            line = line[:-1]
            testing_set.append(line)
    print("Generating TESTING input...")
    test_data, test_labels = onehot.generate_input(testing_set, total_features)  # perform one-hot encoding
    return test_data, test_labels


def create_adversarial_pattern(input_x, input_y):
    """
    FGSM attack as described in https://arxiv.org/pdf/1412.6572.pdf
    The goal of FGSM is to cause the loss function to increase for specific inputs.
    It operates by perturbating each feature of an input x by a small value to maximize the loss.
    Steps:
    1)Compute the gradient of the loss with respect to the input
                            ∇_x J(θ,x,y)
      where x is the model's input, y the target class, θ the model's parameters, ∇_x the gradient and J(θ,x,y) the loss
    2)Take the sign of the gradient (calculated in 1), multiply it by a threshold ε and add it to the
       original input x.
                            x_adv=x+e*sign(∇_x J(θ,x,y))

    :param input_x: the original input data
    :param input_y: the original input label
    :return: the sign of the gradient
    """
    with tf.GradientTape() as tape:
        tape.watch(input_x)
        prediction = trained_model(input_x)  # predict original input
        loss = loss_object(input_y, prediction)  # get the loss
    # get the gradients of the loss with respect to the inputs
    gradient = tape.gradient(loss, input_x)
    # get the sign of the gradients to create perturbations
    signed_grad = tf.sign(gradient)
    return signed_grad


if __name__ == "__main__":
    total_features = 545333  # total unique features
    print("Creating data-labels...")
    onehot.create_list_of_apps()  # function from set_one_encoding.py
    # path to the saved model
    trained_model = tf.keras.models.load_model('models_incremental_learning/model_Adam.h5')

    # create the testing input
    val_data, val_labels = create_set()

    # loss function
    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()
    val_data = tf.convert_to_tensor(val_data, dtype=np.float32)
    val_labels = tf.convert_to_tensor(val_labels, dtype=np.int32)

    perturbations = create_adversarial_pattern(val_data, val_labels)  # get the sign of gradient wrt the input

    epsilons = [0, 0.01]  # 0 to evaluate without FGSM, 0.01 for FGSM. Note 0.01 is too small, but able to fool models!
    descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')
                    for eps in epsilons]

    for i, eps in enumerate(epsilons):
        adv_x = val_data + eps * perturbations  # compute input_x + eps * adversarial examples as defined in FGSM
        adv_x = tf.clip_by_value(adv_x, 0, 1)
        prediction = trained_model.predict(adv_x)  # model prediction
        confusion = confusion_matrix(val_labels, np.argmax(prediction, axis=1))  # confusion matrix
        print(confusion)
        # confusion matrix metrics
        TP = confusion[1, 1]
        TN = confusion[0, 0]
        FP = confusion[0, 1]
        FN = confusion[1, 0]
        FNR = FN / float(FN + TP) * 100
        FPR = FP / float(FP + TN) * 100
        accuracy = (TP + TN) / float(TP + TN + FP + FN) * 100
        print("Epsilon:", eps, "- FP:", FP, "- FN:", FN, "- TP:", TP, "- TN", TN)
        print("Epsilon:", eps, "- Accuracy:", accuracy, "- FPR:", FPR, "- FNR:", FNR)
        print("Misclassification Rate:", 100 - accuracy)
