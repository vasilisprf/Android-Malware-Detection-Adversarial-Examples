import set_onehot_encoding as onehot
import models
import neural_network as NN
import numpy as np


def create_random_sets():
    print("Generating TRAINING set...")
    training_set = onehot.generate_set(set_size, malware_ratio)  # generate random training set
    print("Generating TRAINING input...")
    data, labels = onehot.generate_input(training_set, total_features)  # perform one-hot encoding
    print("Generating TESTING set...")
    testing_set = onehot.generate_set(testing_set_size, malware_ratio)  # generate random testing set
    print("Generating TESTING input...")
    test_data, test_labels = onehot.generate_input(testing_set, total_features)  # perform one-hot encoding
    return data, labels, test_data, test_labels  # return train data - labels and test data - labels


def random_sub_sampling(runs):
    score_gnb = []  # score for gaussian naive bayes
    score_mnb = []  # scores for multinomial naive bayes
    score_cnb = []  # scores for complement naive bayes
    score_bnb = []  # scores for bernoulli naive bayes
    score_dt = []  # scores for decision trees
    score_rf = []  # scores for random forest
    score_knn = []  # scores for k nearest neighbors
    score_lr = []  # scores for logistic regression
    score_svm = []  # scores for support vector machines
    score_nn = []  # scores for neural network

    for i in range(runs):

        data, labels, test_data, test_labels = create_random_sets()  # choose random training and testing sets

        #model = GNB.train_gaussian_naive_bayes_classifier(data, labels)  # train Gaussian Naive Bayes
        #score_gnb = GNB.evaluate_gaussian_naive_bayes_classifier(model, test_data, test_labels)  # evaluate performance

        #model = MNB.train_multi_naive_bayes_classifier(data, labels)  # train Multinomial Naive Bayes
        #score_mnb = MNB.evaluate_multi_naive_bayes_classifier(model, test_data, test_labels)

        #model = CNB.train_complement_naive_bayes_classifier(data, labels)  # train Complement Naive Bayes
        #score_cnb = CNB.evaluate_complement_naive_bayes_classifier(model, test_data, test_labels)

        #model = BNB.train_bernoulli_naive_bayes_classifier(data, labels)  # train Bernoulli Naive Bayes
        #score_bnb = BNB.evaluate_bernoulli_naive_bayes_classifier(model, test_data, test_labels)

        #model = DT.train_decision_tree_classifier(data, labels)  # train Decision Tree Classifier
        #score_dt = DT.evaluate_decision_tree_classifier(model, test_data, test_labels)

        #model = RF.train_random_forest_classifier(data, labels)  # train Random Forest
        #score_rf = RF.evaluate_random_forest_classifier(model, test_data, test_labels)

        #model = KNN.train_knn_classifier(data, labels)  # train k-Nearest Neighbors Classifier
        #score_knn = KNN.evaluate_knn_classifier(model, test_data, test_labels)

        #model = LR.train_logistic_regression_classifier(data, labels)  # train logistic Regression
        #score_lr = LR.evaluate_logistic_regression_classifier(model, test_data, test_labels)

        #model = SVM.train_svm_classifier(data, labels)  # train Support Vector Machines
        #score_svm = SVM.evaluate_svm_classifier(model, test_data, test_labels)

        # init neural net
        model = NN.generate_neural_network(total_features, units, dropout, learn_rate, kernel_initializer,
                                           bias_initializer, activation_function)
        """
        this is not the actual training procedure and we don't want to save the models. To save models and implement
        the early stopping technique refer to train_models.py
        The goal of this operation is only to determine the behavior of models to random training sets and random
        testing sets!
        So, only train and evaluate models.
        """
        NN.train_neural_network(model, epochs, batch_size, data, labels, verbose=2)
        score = NN.evaluate_neural_network(model, test_data, test_labels)
        score_nn.append(score)

    # get average accuracy and standard deviation for each model for each model
    #print("NB Average accuracy: ", np.mean(score_gnb), "Standard Deviation:", np.std(score_gnb))
    #print("MNB Average accuracy: ", np.mean(score_mnb), "Standard Deviation:", np.std(score_mnb))
    #print("CNB Average accuracy: ", np.mean(score_cnb), "Standard Deviation:", np.std(score_cnb))
    #print("BNB Average accuracy: ", np.mean(score_bnb), "Standard Deviation:", np.std(score_bnb))
    #print("DT Average accuracy: ", np.mean(score_dt), "Standard Deviation:", np.std(score_dt))
    #print("RF Average accuracy: ", np.mean(score_rf), "Standard Deviation:", np.std(score_rf))
    #print("kNN Average accuracy: ", np.mean(score_knn), "Standard Deviation:", np.std(score_knn))
    #print("LR Average accuracy: ", np.mean(score_lr), "Standard Deviation:", np.std(score_lr))
    #print("SVM Average accuracy: ", np.mean(score_svm), "Standard Deviation:", np.std(score_svm))
    print("NN Average accuracy: ", np.mean(score_nn), "Standard Deviation:", np.std(score_nn))


if __name__ == "__main__":
    total_features = 545333  # total unique features
    set_size = 1500  # set site that will be used to create random training set
    testing_set_size = 1500  # set site that will be used to create random test set
    malware_ratio = 0.3  # malware ratio in the set size

    print("Creating data-labels...")
    onehot.create_list_of_apps()  # function from set_one_encoding.py

    # initialize sklearn models
    GNB = models.GaussianNaiveBayes()
    MNB = models.MultinomialNaiveBayes()
    CNB = models.ComplementNaiveBayes()
    BNB = models.BernoulliNaiveBayes()
    DT = models.DecisionTree()
    RF = models.RandomForest()
    KNN = models.KNearestNeighbors()
    LR = models.LogRegression()
    SVM = models.SupportVectorMachine()

    val_runs = 8  # number of times to train and test a model

    # neural net parameters
    units = [200, 200]  # number of neurons in each layer (2 hidden layers)
    dropout = 0.001  # dropout rate
    epochs = 4  # epochs per iteration
    batch_size = 150  # batch size
    learn_rate = 0.001  # learning rate of the specified optimizer
    kernel_initializer = 'glorot_uniform'  # weight initialization
    bias_initializer = 'zeros'  # bias initialization
    activation_function = 'relu'  # activation function in hidden layers (We use Softmax in the output layer)

    random_sub_sampling(val_runs)