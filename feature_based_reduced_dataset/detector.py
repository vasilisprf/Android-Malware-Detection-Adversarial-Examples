from sklearn.metrics import confusion_matrix
import timeit
from keras import Sequential
from keras.layers import Dense, Dropout
import numpy as np
import matplotlib.pyplot as plt
from keras.callbacks import TensorBoard
from keras.callbacks import EarlyStopping
from keras.callbacks import ModelCheckpoint
from keras.optimizers import Adam
import os
import set_onehot_encoding as onehot
import tensorflow as tf
from tensorflow import keras
from sklearn.utils import shuffle
import models


def generate_neural_network(total_features, units, dropout, learn_rate, kernel, bias, activation_function, output):
    """
    :param total_features: the total features (input_dim) we used to train our network
    :param units: neurons in the hidden layers
    :param dropout: the dropout rate
    :param learn_rate: learning rate
    :param kernel: (kernel_initializer) weights initialization
    :param bias: (bias_initializer) bias init initialization
    :param activation_function: activation function
    :return:
    """
    model = Sequential()  # neural net init
    """
    add input layer dimension with 545333 features
    hidden layers with the defined units, dropout rate, weight and biases initialization,
    relu activation function and softmax in output layer
    """
    model.add(Dense(units=units[0], activation=activation_function, input_dim=total_features, kernel_initializer=kernel,
                    bias_initializer=bias))
    model.add(Dropout(dropout))  # add dropout rate

    for hidden_layer_units in units[1:]:  # add hidden layers defined units in train_models.py
        model.add(Dense(units=hidden_layer_units, activation=activation_function, kernel_initializer=kernel,
                        bias_initializer=bias))
        model.add(Dropout(dropout))

    model.add(Dense(output, activation="softmax"))  # output layer, with softmax activation function and 2 neurons

    # loss: sparse categorical cross entropy, Optimizer: Adam
    model.compile(loss="sparse_categorical_crossentropy",
                  optimizer=Adam(lr=learn_rate),
                  metrics=["accuracy"])

    """
    information about the NN, such as the number of layers, the output shape, 
    the number of weights in each layer and the total weights.
    """
    #model.summary()

    # plot of the neural network graph
    #plot_model(model, to_file="figures/DNN_model_plot.png", show_shapes=True, show_layer_names=True)

    return model


def train_neural_network(model, epochs, batch_size, features, labels, verbose=0,
                         validation=False, val_data=None, val_labels=None,
                         callbacks=False, plot_history=False, path="logs/fit/", model_name="DNN_200_200"):
    """
    :param modelh5: neural network model from generate_neural_network()
    :param epochs: number of epochs
    :param batch_size: batch size
    :param features: training data
    :param labels: training labels
    :param verbose: verbosity level
    :param validation: if True validate data
    :param val_data: validation data
    :param val_labels: validation labels
    :param callbacks: if True use Tensorboard callback
    :param plot_history: if True plots accuracy and loss history per epoch
    :param path:
    :param model_name:
    :return:
    """
    print("\n\n--- Training", type(model).__name__, "---")
    start_time = timeit.default_timer()

    # get the name of the optimizer in the defined model
    opt_config = model.optimizer.get_config()
    if 'name' not in opt_config.keys():
        _name = str(model.optimizer.__class__).split('.')[-1].replace('\'', '').replace('>', '')
        opt_config.update({'name': _name})

    if callbacks:
        # directory to save callbacks
        log_dir = path + model_name + opt_config['name']
        # callbacks: TensorBoard, EarlyStopping, ModelCheckPoint
        # TensorBoard for storing visualizations of the neural net
        tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)
        # EarlyStopping to monitor validation loss. If there is any improve after 10 epochs,the training procedure stops
        early_stopping_callback = EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=verbose)
        # ModelCheckpoint to monitor validation accuracy. It stores the model with the highest accuracy
        model_checkpoint_callback = ModelCheckpoint('external_detector.h5', monitor='val_accuracy', mode='max',
                                                    verbose=verbose, save_best_only=True)
        if not validation:
            # fit the model
            print("Note: Validation data is not included...Only Tensorboard callback is used!")
            history = model.fit(features, labels, epochs=epochs, batch_size=batch_size, verbose=verbose,
                                callbacks=[tensorboard_callback])  # train the neural network
        else:
            # fit the model
            history = model.fit(features, labels, epochs=epochs, batch_size=batch_size, verbose=verbose,
                                validation_data=(val_data, val_labels),
                                callbacks=[tensorboard_callback, early_stopping_callback, model_checkpoint_callback])
    else:  # train the model without the use of callbacks
        history = model.fit(features, labels, epochs=epochs, batch_size=batch_size, verbose=verbose)

    if plot_history:  # plots the accuracy and loss per epoch
        if validation:
            # summarize history for training and validation accuracy
            plt.plot(history.history['accuracy'])
            plt.plot(history.history['val_accuracy'])
            plt.title('model accuracy')
            plt.ylabel('accuracy')
            plt.xlabel('epoch')
            plt.legend(['train', 'test'], loc='upper left')
            plt.show()
            # summarize history for training and validation loss
            plt.plot(history.history['loss'])
            plt.plot(history.history['val_loss'])
            plt.title('model loss')
            plt.ylabel('loss')
            plt.xlabel('epoch')
            plt.legend(['train', 'test'], loc='upper left')
            plt.show()
        else:
            # print(history.history.keys())
            # summarize history for training accuracy
            plt.plot(history.history['accuracy'])
            plt.title('model accuracy')
            plt.ylabel('accuracy')
            plt.xlabel('epoch')
            plt.legend(['train'], loc='upper left')
            plt.show()
            # summarize history for training loss
            plt.plot(history.history['loss'])
            plt.title('model loss')
            plt.ylabel('loss')
            plt.xlabel('epoch')
            plt.legend(['train'], loc='upper left')
            plt.show()

    stop_time = timeit.default_timer()
    print(type(model).__name__, "training time: ", stop_time - start_time, "seconds\n\n")

"""
functions to compute Jacobian with numpy.
https://medium.com/unit8-machine-learning-publication/computing-the-jacobian-matrix-of-a-neural-network-in-python-4f162e5db180
First we specify the the forward and backward passes of each layer to implement backpropagation manually.
"""


def affine_forward(x, w, b):
    """
    Forward pass of an affine layer
    :param x: input of dimension (I, )
    :param w: weights matrix of dimension (I, O)
    :param b: biais vector of dimension (O, )
    :return output of dimension (O, ), and cache needed for backprop
    """
    out = np.dot(x, w) + b
    cache = (x, w)
    return out, cache


def affine_backward(dout, cache):
    """
    Backward pass for an affine layer.
    :param dout: Upstream Jacobian, of shape (M, O)
    :param cache: Tuple of:
      - x: Input data, of shape (I, )
      - w: Weights, of shape (I, O)
    :return the jacobian matrix containing derivatives of the M neural network outputs with respect to
            this layer's inputs, evaluated at x, of shape (M, I)
    """
    x, w = cache
    dx = np.dot(dout, w.T)
    return dx


def relu_forward(x):
    """ Forward ReLU
    """
    out = np.maximum(np.zeros(x.shape), x)
    cache = x
    return out, cache


def relu_backward(dout, cache):
    """
    Backward pass of ReLU
    :param dout: Upstream Jacobian
    :param cache: the cached input for this layer
    :return: the jacobian matrix containing derivatives of the M neural network outputs with respect to
             this layer's inputs, evaluated at x.
    """
    x = cache
    dx = dout * np.where(x > 0, np.ones(x.shape), np.zeros(x.shape))
    return dx


def softmax_forward(x):
    """ Forward softmax
    """
    exps = np.exp(x - np.max(x))
    s = exps / exps.sum()
    return s, s


def softmax_backward(dout, cache):
    """
    Backward pass for softmax
    :param dout: Upstream Jacobian
    :param cache: contains the cache (in this case the output) for this layer
    """
    s = cache
    ds = np.diag(s) - np.outer(s, s.T)
    dx = np.dot(dout, ds)
    return dx


def get_activations(model, layer_id, X):
    """
    Computes outputs of intermediate layers
    :param model: the trained model
    :param layer_id: the id of the layer that we want the output from
    :param X: input feature vector
    :return: output of layer (layer_id)
    """
    intermediate_layer_model = keras.models.Model(inputs=model.input,
                                                  outputs=model.layers[layer_id].output)
    intermediate_output = intermediate_layer_model.predict(X)
    return intermediate_output


def forward_backward(model, x):
    """
    computes the forward derivative for the given input
    :param model: the trained model
    :param x: input feature vector
    :return: prediction result and forward derivative
    """
    layer_to_cache = dict()  # for each layer, we store the cache needed for backward pass
    forward_values = []

    for i in range(0, len(model.layers), 2):
        values = {}
        w, b = model.layers[i].get_weights()
        values['w'] = w
        values['b'] = b
        forward_values.append(values)

    # Forward pass
    a1, cache_a1 = affine_forward(x, forward_values[0]['w'], forward_values[0]['b'])
    _, cache_r1 = relu_forward(a1)
    r1 = get_activations(model, 0, x)
    forward_values[0]['a'] = a1
    forward_values[0]['cache_a'] = cache_a1
    forward_values[0]['r'] = r1
    forward_values[0]['cache_r'] = cache_r1

    for i, layer_index in zip(range(1, len(forward_values) - 1), range(2, len(model.layers), 2)):
        a, cache_a = affine_forward(forward_values[i - 1]['r'], forward_values[i]['w'], forward_values[i]['b'])
        _, cache_r = relu_forward(a)
        r = get_activations(model, layer_index, x)
        forward_values[i]['a'] = a
        forward_values[i]['cache_a'] = cache_a
        forward_values[i]['r'] = r
        forward_values[i]['cache_r'] = cache_r

    a, cache_a = affine_forward(forward_values[len(forward_values) - 2]['r'],
                                forward_values[len(forward_values) - 1]['w'],
                                forward_values[len(forward_values) - 1]['b'])
    forward_values[len(forward_values) - 1]['a'] = a
    forward_values[len(forward_values) - 1]['cache_a'] = cache_a
    out, cache_out = softmax_forward(a)

    # backward pass
    dout = np.diag(np.ones(out.size, ))  # the derivatives of each output w.r.t. each output.
    dout = softmax_backward(dout, cache_out)
    dout = affine_backward(dout, forward_values[len(forward_values) - 1]['cache_a'])

    for i in range(len(forward_values) - 2, 0, -1):
        dout = relu_backward(dout, forward_values[i]['cache_r'])
        dout = affine_backward(dout, forward_values[i]['cache_a'])

    dout = relu_backward(dout, forward_values[0]['cache_r'])
    dx = affine_backward(dout, forward_values[0]['cache_a'])

    return out, dx


def craft_adversarial_samples(x, y, F, k):

    x_adv = x
    gamma = [1] * len(x)
    delta_x = [0]
    changes = 0

    if np.argmax(F.predict(x_adv), 1) == 0:  # if misclassification achieved return adv_x
        return x_adv, -1

    while np.argmax(F.predict(x_adv), 1) != y and np.linalg.norm(delta_x, ord=1) < k and changes < 20:
        # compute forward derivative (Jacobian)
        prob, forward_derivative = forward_backward(F, x_adv)

        tmp = np.multiply(forward_derivative[0], gamma)
        for i, feature in enumerate(x_adv[0]):
            if feature == 1:
                tmp[i] = 0
        i_max = np.argmax(tmp)
        if i_max <= 0:
            raise ValueError('FAILURE: We can only add features to an application!')

        x_adv[0][i_max] = 1
        delta_x = np.subtract(x_adv, x)
        # print(i_max)
        if i_max not in changes_dict:
            changes_dict[i_max] = 1
        else:
            changes_dict[i_max] += 1
        changes += 1
    print("Changes:", changes)

    return x_adv, changes


def train_original():
    train_data, train_labels = create_training_set()
    test_data, test_labels = create_testing_set()
    model = generate_neural_network(total_features, [200, 200], 0.2, 0.001, "glorot_uniform", "zeros", "relu", 2)
    train_neural_network(model, epochs=4, batch_size=150, features=train_data, labels=train_labels, verbose=2)
    model.save(dir_path + "original")
    del model

    # evaluate the saved model
    trained_model = tf.keras.models.load_model(dir_path + "original")
    predict_original = trained_model.predict(test_data)
    confusion = confusion_matrix(test_labels, np.argmax(predict_original, axis=1))
    TP = confusion[1, 1]
    TN = confusion[0, 0]
    FP = confusion[0, 1]
    FN = confusion[1, 0]
    FNR = FN / float(FN + TP) * 100
    FPR = FP / float(FP + TN) * 100
    accuracy = ((TP + TN) / float(TP + TN + FP + FN)) * 100
    print(confusion)
    print("Original FP:", FP, "- FN:", FN, "- TP:", TP, "- TN", TN)
    print("Original Accuracy:", accuracy, "- FPR:", FPR, "- FNR:", FNR)


def create_sets():
    if os.path.isfile("training_set_2000.txt") is False:
        set_size = 2000
        malware_ratio = 0.3
        print("Creating data-labels...")
        print("Generating TESTING set...")
        training_set = onehot.generate_set(set_size, malware_ratio)  # generate random testing set
        with open("training_set_2000.txt", "w") as file:
            for item in training_set:
                file.write(str(item) + "\n")

    if os.path.isfile("testing_set_2000.txt") is False:
        set_size = 2000
        malware_ratio = 0.3
        print("Creating data-labels...")
        print("Generating TESTING set...")
        testing_set = onehot.generate_set(set_size, malware_ratio)  # generate random testing set
        with open("testing_set_2000.txt", "w") as file:
            for item in testing_set:
                file.write(str(item) + "\n")

    training_set = []
    testing_set = []

    with open("training_set_2000.txt", "r") as file:  # read training set file and append applications to list
        for line in file:
            line.strip()  # remove whitespace
            line = line[:-1]  # remove \n
            training_set.append(line)  # add item to list
    with open("testing_set_2000.txt", "r") as file:  # read testing set file and append applications to list
        for line in file:
            line.strip()
            line = line[:-1]
            testing_set.append(line)
    print("Generating TRAINING input...")
    data, labels = onehot.generate_input(training_set, total_features)  # perform one-hot encoding
    print("Generating TESTING input...")
    test_data, test_labels = onehot.generate_input(testing_set, total_features)  # perform one-hot encoding
    return data, labels, test_data, test_labels


def train_external_detector():

    train_data, train_labels, test_data, test_labels = create_sets()

    trained_model = tf.keras.models.load_model('best_model_Adam.h5')
    predict_original = trained_model.predict(train_data)
    confusion = confusion_matrix(train_labels, np.argmax(predict_original, axis=1))
    TP = confusion[1, 1]
    TN = confusion[0, 0]
    FP = confusion[0, 1]
    FN = confusion[1, 0]
    FNR_original = FN / float(FN + TP) * 100
    FPR = FP / float(FP + TN) * 100
    accuracy = ((TP + TN) / float(TP + TN + FP + FN)) * 100
    print(confusion)
    print("Original FP:", FP, "- FN:", FN, "- TP:", TP, "- TN", TN)
    print("Original Accuracy:", accuracy, "- FPR:", FPR, "- FNR:", FNR_original)
    average_changes = 0
    amount_malwares = 0
    averageChanges = 0

    # the numpy array will be filled dynamically
    adversarial_data = np.zeros((0, 3880), dtype=float)

    for i in range(len(train_data)):
        if train_labels[i] == 1:

            x = train_data[i:i + 1]
            # print("x: ", x)
            # print(x.shape)
            try:
                adv_x, changes = craft_adversarial_samples(x, 0, trained_model, 1)
                # print(adv_x)
                # append the adversarial data to the numpy array
                adversarial_data = np.concatenate((adversarial_data, adv_x))
                if changes >= 0:
                    average_changes += changes
                    amount_malwares += 1
            except NameError:
                pass
            except ValueError:
                pass

    if amount_malwares > 0:
        averageChanges += (average_changes / float(amount_malwares))

    train_data, train_labels, test_data, test_labels = create_sets()
    predictions = trained_model.predict(train_data)
    confusion = confusion_matrix(train_labels, np.argmax(predictions, axis=1))
    print(confusion)
    TP = confusion[1, 1]
    TN = confusion[0, 0]
    FP = confusion[0, 1]
    FN = confusion[1, 0]
    FNR = FN / float(FN + TP) * 100
    FPR = FP / float(FP + TN) * 100
    accuracy = ((TP + TN) / float(TP + TN + FP + FN)) * 100
    print("Adversarial  FP:", FP, "- FN:", FN, "- TP:", TP, "- TN", TN)
    print("Adversarial Accuracy:", accuracy, "- FPR:", FPR, "- FNR:", FNR)
    print("Misclassification Rate:", FNR - FNR_original)
    print("Distortion:", averageChanges)
    predictions = trained_model.predict(adversarial_data)
    adversarial_labels = np.ones((len(adversarial_data),), dtype=int)
    confusion = confusion_matrix(adversarial_labels, np.argmax(predictions, axis=1))
    print(confusion)
    TP = confusion[1, 1]
    TN = confusion[0, 0]
    FP = confusion[0, 1]
    FN = confusion[1, 0]
    FNR = FN / float(FN + TP) * 100
    FPR = FP / float(FP + TN) * 100
    accuracy = ((TP + TN) / float(TP + TN + FP + FN)) * 100
    print("Adversarial  FP:", FP, "- FN:", FN, "- TP:", TP, "- TN", TN)
    print("Adversarial Accuracy:", accuracy, "- FPR:", FPR, "- FNR:", FNR)
    print("Misclassification Rate:", FNR - FNR_original)
    print("Distortion:", averageChanges)
    print(changes_dict)
    del predict_original, FNR_original, predictions, confusion, TP, TN, FP, FN, FNR, FPR, accuracy

    # concatenate legit with produced adversarial input
    final_train_data = np.concatenate((train_data, adversarial_data))
    print("final train data shape:", final_train_data.shape)

    train_labels = np.zeros((len(train_labels),), dtype=int)  # fill with 0 (the original class)
    print("train labels shape:", train_labels.shape)

    adverarial_labels = np.ones((len(adversarial_data),), dtype=int)  # fill with 1 (the adversarial class)
    print("adversarial labels:", adverarial_labels.shape)

    final_train_labels = np.concatenate((train_labels, adverarial_labels))
    print("final labels shape:", final_train_labels.shape)
    print("Unique classes:", np.unique(final_train_labels))

    del train_data, train_labels, adversarial_data, adverarial_labels
    #shuffle the set
    shuffle(final_train_data, final_train_labels, random_state=123)

    # train with the augmented dataset (with adverarial examples belong to class '1')
    model = generate_neural_network(total_features, [200, 200], 0.2, 0.001, "glorot_uniform", "zeros", "relu", 2)
    train_neural_network(model, epochs=30, batch_size=150, features=final_train_data, labels=final_train_labels,
                         verbose=2,
                         validation=True, val_data=final_train_data, val_labels=final_train_labels,
                         callbacks=True, path=dir_path + "logs/fit/", model_name="external_detector_2")
    GNB = models.GaussianNaiveBayes()
    MNB = models.MultinomialNaiveBayes()
    CNB = models.ComplementNaiveBayes()
    BNB = models.BernoulliNaiveBayes()
    DT = models.DecisionTree()
    RF = models.RandomForest()
    KNN = models.KNearestNeighbors()
    LR = models.LogRegression()
    SVM = models.SupportVectorMachine()

    model = GNB.train_gaussian_naive_bayes_classifier(final_train_data, final_train_labels)  # train Naive Bayes
    score_GNB = GNB.evaluate_gaussian_naive_bayes_classifier(model, final_train_data,
                                                             final_train_labels)  # test performance
    print("GNB", score_GNB)

    model = MNB.train_multi_naive_bayes_classifier(final_train_data, final_train_labels)
    score_MNB = MNB.evaluate_multi_naive_bayes_classifier(model, final_train_data, final_train_labels)
    print("MNB", score_MNB)

    model = CNB.train_complement_naive_bayes_classifier(final_train_data, final_train_labels)
    score_CNB = CNB.evaluate_complement_naive_bayes_classifier(model, final_train_data, final_train_labels)
    print("CNB", score_CNB)

    model = BNB.train_bernoulli_naive_bayes_classifier(final_train_data, final_train_labels)
    score_BNB = BNB.evaluate_bernoulli_naive_bayes_classifier(model, test_data, test_labels)
    print("BNB", score_BNB)

    model = DT.train_decision_tree_classifier(final_train_data, final_train_labels)  # train Decision Tree Classifier
    score_dt = DT.evaluate_decision_tree_classifier(model, final_train_data, final_train_labels)
    print("DT:", score_dt)

    model = LR.train_logistic_regression_classifier(final_train_data, final_train_labels)  # train logistic Regression
    score_lr = LR.evaluate_logistic_regression_classifier(model, final_train_data, final_train_labels)
    print("LR", score_lr)

    model = KNN.train_knn_classifier(final_train_data, final_train_labels)  # train k-Nearest Neighbors Classifier
    score_knn = KNN.evaluate_knn_classifier(model, final_train_data, final_train_labels)
    print("KNN", score_knn)

    model = SVM.train_svm_classifier(final_train_data, final_train_labels)  # train Support Vector Machines
    score_svm = SVM.evaluate_svm_classifier(model, final_train_data, final_train_labels)
    print("SVM", score_svm)

    model = RF.train_random_forest_classifier(final_train_data, final_train_labels)  # train Random Forest
    score_rf = RF.evaluate_random_forest_classifier(model, final_train_data, final_train_labels)
    print("RF:", score_rf)


def attack_external_detector():
    train_data, train_labels, test_data, test_labels = create_sets()

    trained_model = tf.keras.models.load_model('external_detector.h5')
    predict_original = trained_model.predict(train_data)
    confusion = confusion_matrix(train_labels, np.argmax(predict_original, axis=1))
    TP = confusion[1, 1]
    TN = confusion[0, 0]
    FP = confusion[0, 1]
    FN = confusion[1, 0]
    FNR_original = FN / float(FN + TP) * 100
    FPR = FP / float(FP + TN) * 100
    accuracy = ((TP + TN) / float(TP + TN + FP + FN)) * 100
    print(confusion)
    print("Original FP:", FP, "- FN:", FN, "- TP:", TP, "- TN", TN)
    print("Original Accuracy:", accuracy, "- FPR:", FPR, "- FNR:", FNR_original)
    average_changes = 0
    amount_malwares = 0
    averageChanges = 0

    # the numpy array will be filled dynamically
    adversarial_data = np.zeros((0, 3880), dtype=float)

    for i in range(len(train_data)):
        if train_labels[i] == 1:

            x = train_data[i:i + 1]
            # print("x: ", x)
            # print(x.shape)
            try:
                adv_x, changes = craft_adversarial_samples(x, 0, trained_model, 1)
                # print(adv_x)
                # append the adversarial data to the numpy array
                adversarial_data = np.concatenate((adversarial_data, adv_x))
                if changes >= 0:
                    average_changes += changes
                    amount_malwares += 1
            except NameError:
                pass
            except ValueError:
                pass

    if amount_malwares > 0:
        averageChanges += (average_changes / float(amount_malwares))

    train_data, train_labels, test_data, test_labels = create_sets()
    predictions = trained_model.predict(train_data)
    confusion = confusion_matrix(train_labels, np.argmax(predictions, axis=1))
    print(confusion)
    TP = confusion[1, 1]
    TN = confusion[0, 0]
    FP = confusion[0, 1]
    FN = confusion[1, 0]
    FNR = FN / float(FN + TP) * 100
    FPR = FP / float(FP + TN) * 100
    accuracy = ((TP + TN) / float(TP + TN + FP + FN)) * 100
    print("Adversarial  FP:", FP, "- FN:", FN, "- TP:", TP, "- TN", TN)
    print("Adversarial Accuracy:", accuracy, "- FPR:", FPR, "- FNR:", FNR)
    print("Misclassification Rate:", FNR - FNR_original)
    print("Distortion:", averageChanges)
    predictions = trained_model.predict(adversarial_data)
    confusion = confusion_matrix(train_labels, np.argmax(predictions, axis=1))
    print(confusion)
    TP = confusion[1, 1]
    TN = confusion[0, 0]
    FP = confusion[0, 1]
    FN = confusion[1, 0]
    FNR = FN / float(FN + TP) * 100
    FPR = FP / float(FP + TN) * 100
    accuracy = ((TP + TN) / float(TP + TN + FP + FN)) * 100
    print("Adversarial  FP:", FP, "- FN:", FN, "- TP:", TP, "- TN", TN)
    print("Adversarial Accuracy:", accuracy, "- FPR:", FPR, "- FNR:", FNR)
    print("Misclassification Rate:", FNR - FNR_original)
    print("Distortion:", averageChanges)
    print(changes_dict)


if __name__ == "__main__":

    dir_path = "external_detector/"

    if not os.path.exists(dir_path):  # check if path exists
        os.mkdir(dir_path)

    total_features = 3880
    onehot.create_list_of_apps()
    changes_dict = {}

    # if you want to train a new model (we use the model generated in previous stage)
    #train_original()
    #train_external_detector()
    #attack_external_detector()

